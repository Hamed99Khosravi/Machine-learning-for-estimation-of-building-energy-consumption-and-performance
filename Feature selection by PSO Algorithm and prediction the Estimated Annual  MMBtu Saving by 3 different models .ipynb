{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('nf.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop([ 'Estimated Annual kWh Savings','First Year Energy Savings $ Estimate'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57924, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "from pso import PSO,Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (34754, 80) (34754,)\n",
      "Testing dataset shape: (11585, 80) (11585,)\n",
      "Validation dataset shape: (11585, 80) (11585,)\n",
      "(57924, 81)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from bga import BGA\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "def Fitness(arr , x_train, y_train , x_validate , y_validate):\n",
    "    index = [i for i, e in enumerate(arr) if e == 1]\n",
    "    index = np.array(index)\n",
    "  \n",
    "    x_train_new = x_train.iloc[:,index] \n",
    "    print(x_train_new.shape)\n",
    "    x_val_new = x_validate.iloc[:,index]\n",
    "   \n",
    "    regressor=Lasso(alpha=0.005,max_iter=100,normalize=False,tol=0.0005)\n",
    "    regressor.fit(x_train_new,y_train)\n",
    "    #Lasso(alpha=1.0,max_iter=1000,normalize=False,tol=0.0001,fit_intercept=True,precompute=False,copy_X=True,warm_start=False,positive=False,random_state=None,selection='cyclic')\n",
    "    #regressor=DecisionTreeRegressor(criterion='mse',max_features= 2,min_samples_leaf=1,min_samples_split=2)\n",
    "    #regressor.fit(x_train_new,y_train)\n",
    "    #DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
    "     #                   max_features=2, max_leaf_nodes=None,\n",
    "      #                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       #                 min_samples_leaf=1, min_samples_split=2,\n",
    "        #                min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "         #               random_state=None, splitter='best')\n",
    "    yp=regressor.predict(x_val_new)\n",
    "    mse = mean_squared_error(y_validate,yp)\n",
    "    Rmse=m.sqrt(mse)\n",
    "    AIC=(34754)*m.log(Rmse)+2*len(index)\n",
    "    print(AIC)\n",
    "    return  AIC \n",
    "\n",
    "\n",
    "\n",
    "train,validate,test=np.split(df1.sample(frac=1),[int(.6*len(df1)),int(.8*len(df1))])\n",
    "x_train=train.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_train=train.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_test=test.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_test=test.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_validate=validate.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_validate=validate.loc[:,'Estimated Annual MMBtu Savings']\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', x_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', x_test.shape, y_test.shape)\n",
    "print('Validation dataset shape:', x_validate.shape, y_validate.shape)\n",
    "print(df1.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)\n",
    "# best_solution, best_fitness = pso.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimentions = 80\n",
    "num_particles = 100\n",
    "maxiter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "(34754, 36)\n",
      "107626.94145898656\n",
      "(34754, 45)\n",
      "108842.80898512258\n",
      "(34754, 38)\n",
      "107053.24165854599\n",
      "(34754, 47)\n",
      "105902.19871100134\n",
      "(34754, 34)\n",
      "106045.79805484321\n",
      "(34754, 49)\n",
      "107182.64384984584\n",
      "(34754, 46)\n",
      "108702.1851640767\n",
      "(34754, 45)\n",
      "107709.31261678113\n",
      "(34754, 53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1710404.3566941675, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106698.00886831679\n",
      "(34754, 44)\n",
      "106045.14178450566\n",
      "(34754, 41)\n",
      "108912.77201878803\n",
      "(34754, 36)\n",
      "109294.35638541204\n",
      "(34754, 39)\n",
      "108234.40173490215\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41978.45200310275, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109322.26103999972\n",
      "(34754, 36)\n",
      "107212.85995744837\n",
      "(34754, 45)\n",
      "106399.94762510511\n",
      "(34754, 38)\n",
      "111957.06685959593\n",
      "(34754, 33)\n",
      "107494.8368269098\n",
      "(34754, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7744983.992159293, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107457.40212627912\n",
      "(34754, 40)\n",
      "104861.44922267998\n",
      "(34754, 33)\n",
      "111804.17390052513\n",
      "(34754, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5911970.828476199, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110977.11400113761\n",
      "(34754, 37)\n",
      "109638.60784508978\n",
      "(34754, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2136469.295305496, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106135.75258361842\n",
      "(34754, 38)\n",
      "106973.18872750395\n",
      "(34754, 41)\n",
      "108480.6784489107\n",
      "(34754, 35)\n",
      "105932.30242918132\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14279.041912976652, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110287.04509735292\n",
      "(34754, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47569.00630598888, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109664.22579410081\n",
      "(34754, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2008117.4377474422, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106563.23816677077\n",
      "(34754, 45)\n",
      "108041.59780571151\n",
      "(34754, 37)\n",
      "106747.44455339544\n",
      "(34754, 41)\n",
      "105379.06070342717\n",
      "(34754, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4192799.785238758, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106103.4981907639\n",
      "(34754, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6700028.62344714, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105296.4868778654\n",
      "(34754, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7440143.49589281, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106368.29161416824\n",
      "(34754, 40)\n",
      "105957.85753511699\n",
      "(34754, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8712621.483552031, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108620.56273837744\n",
      "(34754, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7827781.599551593, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107352.5847237397\n",
      "(34754, 43)\n",
      "106514.59260732486\n",
      "(34754, 42)\n",
      "107472.5604585193\n",
      "(34754, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7073373.400346818, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105890.66159183955\n",
      "(34754, 37)\n",
      "108527.45760027305\n",
      "(34754, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6403126.191648804, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106471.98970750035\n",
      "(34754, 40)\n",
      "106062.08607258949\n",
      "(34754, 37)\n",
      "112889.93216597351\n",
      "(34754, 42)\n",
      "110791.67913911413\n",
      "(34754, 45)\n",
      "105631.01404131058\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7524944.963877836, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107935.91158895724\n",
      "(34754, 36)\n",
      "113146.61741068662\n",
      "(34754, 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9683331.82037921, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110955.36297038845\n",
      "(34754, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7510032.421947275, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105852.4403313412\n",
      "(34754, 42)\n",
      "105432.7187697738\n",
      "(34754, 43)\n",
      "108192.81900150851\n",
      "(34754, 36)\n",
      "111882.75938679649\n",
      "(34754, 40)\n",
      "109757.87596901563\n",
      "(34754, 37)\n",
      "107999.77526915573\n",
      "(34754, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5068599.300471166, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105628.79557266537\n",
      "(34754, 32)\n",
      "106432.44837965391\n",
      "(34754, 40)\n",
      "106809.87193290684\n",
      "(34754, 43)\n",
      "106032.77902774919\n",
      "(34754, 40)\n",
      "109564.3674191307\n",
      "(34754, 37)\n",
      "107278.67128096048\n",
      "(34754, 39)\n",
      "109339.34794667932\n",
      "(34754, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7690681.084731876, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106311.36691185454\n",
      "(34754, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6839410.286386764, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106117.01860415285\n",
      "(34754, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7104475.351734158, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106187.17638670775\n",
      "(34754, 41)\n",
      "111271.72159371406\n",
      "(34754, 39)\n",
      "111039.78593158837\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68618.9305499252, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105612.835523072\n",
      "(34754, 38)\n",
      "110981.61144825126\n",
      "(34754, 40)\n",
      "108025.48224678665\n",
      "(34754, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1387755.4209481552, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110416.14281502577\n",
      "(34754, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3219484.546618347, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106030.91726788631\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89711.81381953508, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108759.42809095765\n",
      "(34754, 36)\n",
      "111723.45723836626\n",
      "(34754, 35)\n",
      "107226.2348410602\n",
      "(34754, 42)\n",
      "106626.20342485994\n",
      "(34754, 37)\n",
      "106159.63489933332\n",
      "(34754, 44)\n",
      "107461.25021743751\n",
      "(34754, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3755666.26099311, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109524.77995294615\n",
      "(34754, 41)\n",
      "112145.94530418461\n",
      "(34754, 42)\n",
      "105750.05834918226\n",
      "(34754, 45)\n",
      "108523.59995584894\n",
      "(34754, 42)\n",
      "108209.27113273209\n",
      "(34754, 37)\n",
      "107204.24664886887\n",
      "(34754, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4313371.615814726, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109847.89887653521\n",
      "(34754, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17916.90636242926, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108549.04940767851\n",
      "(34754, 37)\n",
      "109240.91789704033\n",
      "(34754, 39)\n",
      "110973.66729767837\n",
      "(34754, 40)\n",
      "106611.40423238839\n",
      "(34754, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5665169.728693884, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106290.99380699791\n",
      "(34754, 33)\n",
      "112464.9869738694\n",
      "(34754, 33)\n",
      "107540.64333804646\n",
      "(34754, 37)\n",
      "107116.18854740533\n",
      "(34754, 29)\n",
      "106928.3996036729\n",
      "(34754, 37)\n",
      "106243.32158595766\n",
      "(34754, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8567115.879321154, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108816.90295670938\n",
      "(34754, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3722819.3418914564, tolerance: 13427.232619626515\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107090.16845570464\n",
      "(34754, 41)\n",
      "109054.24464756597\n",
      "optimization results\n",
      "Best Solution is: \n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]\n",
      "Best Fitness is: \n",
      "104861.44922267998\n"
     ]
    }
   ],
   "source": [
    "best_solution, best_fitness = pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (34754, 80) (34754,)\n",
      "Testing dataset shape: (11585, 80) (11585,)\n",
      "Validation dataset shape: (11585, 80) (11585,)\n",
      "(57924, 81)\n"
     ]
    }
   ],
   "source": [
    "best_solution=[1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0]\n",
    "train,validate,test=np.split(df1.sample(frac=1),[int(.6*len(df1)),int(.8*len(df1))])\n",
    "x_train=train.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_train=train.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_test=test.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_test=test.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_validate=validate.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_validate=validate.loc[:,'Estimated Annual MMBtu Savings']\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', x_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', x_test.shape, y_test.shape)\n",
    "print('Validation dataset shape:', x_validate.shape, y_validate.shape)\n",
    "print(df1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from bga import BGA\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34754, 40)\n",
      "(11585, 40)\n",
      "105860.09557351675\n",
      "20.98234092242163\n"
     ]
    }
   ],
   "source": [
    "best_feature_selected = [i for i, e in enumerate(best_solution) if e == 1]\n",
    "x_train_new = x_train.iloc[:,best_feature_selected] \n",
    "print(x_train_new.shape)\n",
    "# x_val_new = x_validate.iloc[:,index]\n",
    "\n",
    "regressor=Lasso(alpha=0.005,max_iter=100,normalize=False,tol=0.0005)\n",
    "regressor.fit(x_train_new,y_train)\n",
    "\n",
    "\n",
    "x_test_new = x_test.iloc[:,best_feature_selected]\n",
    "print(x_test_new.shape)\n",
    "yp=regressor.predict(x_test_new)\n",
    "mse = mean_squared_error(y_test,yp)\n",
    "Rmse=m.sqrt(mse)\n",
    "AIC=(34754)*m.log(Rmse)+2*40\n",
    "print(AIC)\n",
    "print(Rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.658937659316596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                               'Total Project Cost',\n",
       "                                         'Amount Financed Through Program',\n",
       "                                                         'Year Home Built',\n",
       "                                                          'Volume of Home',\n",
       "                                                           'Customer Type',\n",
       "                                                     'Project County_Erie',\n",
       "                                                  'Project County_Suffolk',\n",
       "                                              'Project County_Westchester',\n",
       "                                                'Project County_Jefferson',\n",
       "                                                    'Project City_Buffalo',\n",
       "                                                    'Project City_Webster',\n",
       "                                                  'Project City_Pittsford',\n",
       "                                    'Gas Utility_Rochester Gas & Electric',\n",
       "                               'Gas Utility_Central Hudson Gas & Electric',\n",
       "                                          'Gas Utility_Saint Lawrence Gas',\n",
       "                                              'Gas Utility_KeySpan Energy',\n",
       "                                 'Gas Utility_Long Island Power Authority',\n",
       "                                             'Gas Utility_No Gas Provider',\n",
       "                            'Electric Utility_Long Island Power Authority',\n",
       "                                    'Electric Utility_Consolidated Edison',\n",
       "                          'Electric Utility_Central Hudson Gas & Electric',\n",
       "                                      'Electric Utility_Orange & Rockland',\n",
       "                                                                      2010,\n",
       "                                                                      2013,\n",
       "                                                                      2015,\n",
       "                                                                      2016,\n",
       "                                                                      2017,\n",
       "                                                                      2018,\n",
       "                                                                      2019,\n",
       "                                  'Type of Program Financing_not financed',\n",
       "       'Type of Program Financing_Green Jobs - Green NY Smart Energy Loan',\n",
       "                                        'Type of Program Financing_ESMART',\n",
       "                                 'Pre-Retrofit Home Heating Fuel Type_Oil',\n",
       "                             'Pre-Retrofit Home Heating Fuel Type_Propane',\n",
       "                         'Pre-Retrofit Home Heating Fuel Type_Electricity',\n",
       "                        'Pre-Retrofit Home Heating Fuel Type_Wood Pellets',\n",
       "                                'Pre-Retrofit Home Heating Fuel Type_Coal',\n",
       "                     'Pre-Retrofit Home Heating Fuel Type_Bituminous Coal',\n",
       "                     'Pre-Retrofit Home Heating Fuel Type_Anthracite Coal',\n",
       "                                             'Measure Type_Building Shell'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (34754, 80) (34754,)\n",
      "Testing dataset shape: (11585, 80) (11585,)\n",
      "Validation dataset shape: (11585, 80) (11585,)\n",
      "(57924, 81)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from bga import BGA\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "def Fitness(arr , x_train, y_train , x_validate , y_validate):\n",
    "    index = [i for i, e in enumerate(arr) if e == 1]\n",
    "    index = np.array(index)\n",
    "  \n",
    "    x_train_new = x_train.iloc[:,index] \n",
    "    print(x_train_new.shape)\n",
    "    x_val_new = x_validate.iloc[:,index]\n",
    "   \n",
    "    #regressor=Lasso(alpha=0.05,max_iter=100,normalize=True,tol=0.0001)\n",
    "    #regressor.fit(x_train_new,y_train)\n",
    "    #Lasso(alpha=1.0,max_iter=1000,normalize=False,tol=0.0001,fit_intercept=True,precompute=False,copy_X=True,warm_start=False,positive=False,random_state=None,selection='cyclic')\n",
    "    regressor=DecisionTreeRegressor(criterion='mse',max_features= 3,min_samples_leaf=2,min_samples_split=8)\n",
    "    regressor.fit(x_train_new,y_train)#criterion=friedman_mse,max_features=3,min_samples_leaf=5,min_samples_split=12\n",
    "    #DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
    "     #                   max_features=2, max_leaf_nodes=None,\n",
    "      #                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       #                 min_samples_leaf=1, min_samples_split=2,\n",
    "        #                min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "         #               random_state=None, splitter='best')\n",
    "    yp=regressor.predict(x_val_new)\n",
    "    mse = mean_squared_error(y_validate,yp)\n",
    "    Rmse=m.sqrt(mse)\n",
    "    AIC=(34754)*m.log(Rmse)+2*len(index)\n",
    "    print(AIC)\n",
    "    return  AIC \n",
    "\n",
    "train,validate,test=np.split(df1.sample(frac=1),[int(.6*len(df1)),int(.8*len(df1))])\n",
    "x_train=train.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_train=train.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_test=test.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_test=test.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_validate=validate.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_validate=validate.loc[:,'Estimated Annual MMBtu Savings']\n",
    "\n",
    "\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', x_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', x_test.shape, y_test.shape)\n",
    "print('Validation dataset shape:', x_validate.shape, y_validate.shape)\n",
    "print(df1.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)\n",
    "# best_solution, best_fitness = pso.run()\n",
    "\n",
    "# call BGA\n",
    "#test = BGA( x_train, y_train , x_test , y_test, pop_shape=(num_pop, problem_dimentions), method=Fitness, p_c=0.8, p_m=0.2, maxiter = 100, early_stop_rounds=None, verbose = None, maximum=False)\n",
    "\n",
    "# Run BGA\n",
    "#best_solution, best_fitness = test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimentions = 80\n",
    "num_particles = 1000\n",
    "maxiter =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "(34754, 32)\n",
      "111927.68288101858\n",
      "(34754, 44)\n",
      "113592.31367566016\n",
      "(34754, 41)\n",
      "111614.07389952563\n",
      "(34754, 43)\n",
      "109509.7646191928\n",
      "(34754, 41)\n",
      "113916.33934457581\n",
      "(34754, 47)\n",
      "113440.88191977474\n",
      "(34754, 38)\n",
      "114517.00079098986\n",
      "(34754, 33)\n",
      "112013.74382602723\n",
      "(34754, 41)\n",
      "112372.10155059751\n",
      "(34754, 43)\n",
      "112719.95837534942\n",
      "(34754, 43)\n",
      "111183.41858531625\n",
      "(34754, 38)\n",
      "112346.28441950787\n",
      "(34754, 49)\n",
      "109805.53896609024\n",
      "(34754, 36)\n",
      "113157.00407094769\n",
      "(34754, 42)\n",
      "112698.16106801566\n",
      "(34754, 32)\n",
      "110938.66145883869\n",
      "(34754, 34)\n",
      "110047.81640628206\n",
      "(34754, 45)\n",
      "110857.6758374277\n",
      "(34754, 47)\n",
      "112150.05276136295\n",
      "(34754, 40)\n",
      "111438.82228107688\n",
      "(34754, 47)\n",
      "110498.71003344942\n",
      "(34754, 35)\n",
      "114513.22980329675\n",
      "(34754, 35)\n",
      "111002.62176388004\n",
      "(34754, 41)\n",
      "112570.2807139409\n",
      "(34754, 36)\n",
      "110187.54273061927\n",
      "(34754, 39)\n",
      "111355.63049224559\n",
      "(34754, 50)\n",
      "111165.56544832024\n",
      "(34754, 46)\n",
      "112474.54846763442\n",
      "(34754, 40)\n",
      "112982.98977005556\n",
      "(34754, 33)\n",
      "111094.30777774169\n",
      "(34754, 44)\n",
      "112915.71499614356\n",
      "(34754, 36)\n",
      "110099.92543861493\n",
      "(34754, 39)\n",
      "113975.647337315\n",
      "(34754, 46)\n",
      "109300.97378646303\n",
      "(34754, 39)\n",
      "111099.66768416991\n",
      "(34754, 40)\n",
      "111094.5060403133\n",
      "(34754, 33)\n",
      "112247.71266802367\n",
      "(34754, 44)\n",
      "109658.2759990858\n",
      "(34754, 42)\n",
      "109687.42116172228\n",
      "(34754, 34)\n",
      "112216.29553747183\n",
      "(34754, 39)\n",
      "109626.26833112157\n",
      "(34754, 38)\n",
      "110189.08831239038\n",
      "(34754, 49)\n",
      "110629.31554644924\n",
      "(34754, 46)\n",
      "111735.51979682235\n",
      "(34754, 42)\n",
      "112335.3730161415\n",
      "(34754, 37)\n",
      "110630.76231011353\n",
      "(34754, 43)\n",
      "110245.05919548361\n",
      "(34754, 38)\n",
      "109693.46311815678\n",
      "(34754, 50)\n",
      "110787.40521761168\n",
      "(34754, 43)\n",
      "113086.05263165515\n",
      "(34754, 45)\n",
      "110329.54581150025\n",
      "(34754, 29)\n",
      "112040.20852057268\n",
      "(34754, 46)\n",
      "111145.7711496738\n",
      "(34754, 46)\n",
      "110523.66432544301\n",
      "(34754, 39)\n",
      "111198.28932250323\n",
      "(34754, 41)\n",
      "109078.01712855883\n",
      "(34754, 36)\n",
      "113272.74479817123\n",
      "(34754, 45)\n",
      "107817.88718845566\n",
      "(34754, 36)\n",
      "110506.42830959115\n",
      "(34754, 40)\n",
      "109673.196752756\n",
      "(34754, 39)\n",
      "113645.18002127127\n",
      "(34754, 42)\n",
      "108548.3368266078\n",
      "(34754, 40)\n",
      "110809.28673224432\n",
      "(34754, 41)\n",
      "111839.99687141455\n",
      "(34754, 39)\n",
      "114714.94824812589\n",
      "(34754, 46)\n",
      "109390.1319390001\n",
      "(34754, 40)\n",
      "111962.80595051836\n",
      "(34754, 35)\n",
      "111647.71557917591\n",
      "(34754, 46)\n",
      "113162.46442507707\n",
      "(34754, 38)\n",
      "110319.7437926844\n",
      "(34754, 40)\n",
      "111849.75862500047\n",
      "(34754, 34)\n",
      "110852.62200591259\n",
      "(34754, 34)\n",
      "113218.3252170681\n",
      "(34754, 39)\n",
      "110422.27533534417\n",
      "(34754, 41)\n",
      "110034.36424053379\n",
      "(34754, 38)\n",
      "112581.9691252199\n",
      "(34754, 41)\n",
      "110112.68650590462\n",
      "(34754, 40)\n",
      "110561.79412134895\n",
      "(34754, 39)\n",
      "111434.42665980625\n",
      "(34754, 40)\n",
      "112565.7001605262\n",
      "(34754, 29)\n",
      "111841.70345575738\n",
      "(34754, 35)\n",
      "110790.71884201783\n",
      "(34754, 40)\n",
      "111837.64808190572\n",
      "(34754, 40)\n",
      "113958.34166047526\n",
      "(34754, 32)\n",
      "114228.79698769985\n",
      "(34754, 34)\n",
      "112581.13286376983\n",
      "(34754, 45)\n",
      "110053.2997370896\n",
      "(34754, 40)\n",
      "110591.86422173807\n",
      "(34754, 41)\n",
      "111174.02193877113\n",
      "(34754, 33)\n",
      "114533.2310987916\n",
      "(34754, 43)\n",
      "112925.3230265867\n",
      "(34754, 39)\n",
      "109314.454519598\n",
      "(34754, 41)\n",
      "111738.12523096906\n",
      "(34754, 35)\n",
      "112573.66073045923\n",
      "(34754, 36)\n",
      "111880.47742988814\n",
      "(34754, 38)\n",
      "113292.82973293084\n",
      "(34754, 39)\n",
      "112760.60548745526\n",
      "(34754, 33)\n",
      "111155.77858833826\n",
      "(34754, 34)\n",
      "111135.47097925744\n",
      "(34754, 46)\n",
      "110373.45399464441\n",
      "(34754, 37)\n",
      "110583.03442369818\n",
      "(34754, 42)\n",
      "113276.2877593901\n",
      "(34754, 33)\n",
      "109911.23464980834\n",
      "(34754, 45)\n",
      "113793.25251085112\n",
      "(34754, 40)\n",
      "111853.3395224117\n",
      "(34754, 41)\n",
      "111627.82301752828\n",
      "(34754, 33)\n",
      "115778.97413892778\n",
      "(34754, 43)\n",
      "111673.60660737957\n",
      "(34754, 45)\n",
      "111116.5388579036\n",
      "(34754, 48)\n",
      "110257.31560553702\n",
      "(34754, 46)\n",
      "112696.22926817139\n",
      "(34754, 37)\n",
      "109775.25334024159\n",
      "(34754, 38)\n",
      "109567.5266492788\n",
      "(34754, 48)\n",
      "112286.22795330675\n",
      "(34754, 36)\n",
      "112790.71094033695\n",
      "(34754, 46)\n",
      "110241.58860650483\n",
      "(34754, 35)\n",
      "113945.83636881759\n",
      "(34754, 40)\n",
      "111630.78018944533\n",
      "(34754, 44)\n",
      "110483.02347387766\n",
      "(34754, 37)\n",
      "111413.39311376117\n",
      "(34754, 34)\n",
      "112488.30107603616\n",
      "(34754, 31)\n",
      "110444.4155401322\n",
      "(34754, 42)\n",
      "110637.41802135536\n",
      "(34754, 43)\n",
      "111614.05673990744\n",
      "(34754, 43)\n",
      "111721.9385332714\n",
      "(34754, 38)\n",
      "113157.03687343154\n",
      "(34754, 39)\n",
      "112866.35325708379\n",
      "(34754, 41)\n",
      "113512.77934817004\n",
      "(34754, 44)\n",
      "111950.706455654\n",
      "(34754, 49)\n",
      "114012.49097926606\n",
      "(34754, 40)\n",
      "111479.52189393956\n",
      "(34754, 42)\n",
      "112623.60637597044\n",
      "(34754, 42)\n",
      "109503.45334593832\n",
      "(34754, 41)\n",
      "114174.78044591319\n",
      "(34754, 42)\n",
      "111892.25598364761\n",
      "(34754, 33)\n",
      "110074.49314837024\n",
      "(34754, 42)\n",
      "110519.32155083105\n",
      "(34754, 44)\n",
      "111195.4875140995\n",
      "(34754, 34)\n",
      "111420.53226416951\n",
      "(34754, 41)\n",
      "114316.5631725548\n",
      "(34754, 40)\n",
      "110278.30810354666\n",
      "(34754, 39)\n",
      "111853.76406248563\n",
      "(34754, 40)\n",
      "110268.9944128151\n",
      "(34754, 43)\n",
      "111518.78723509407\n",
      "(34754, 48)\n",
      "110152.93110061133\n",
      "(34754, 43)\n",
      "109256.6438860563\n",
      "(34754, 32)\n",
      "113436.33288478076\n",
      "(34754, 41)\n",
      "110929.0078035644\n",
      "(34754, 37)\n",
      "111299.19529114218\n",
      "(34754, 39)\n",
      "112387.86511721315\n",
      "(34754, 42)\n",
      "113719.72274085494\n",
      "(34754, 43)\n",
      "109540.71827321444\n",
      "(34754, 38)\n",
      "112378.85748673706\n",
      "(34754, 38)\n",
      "109866.57265683443\n",
      "(34754, 36)\n",
      "110237.84981366737\n",
      "(34754, 36)\n",
      "110496.04086793988\n",
      "(34754, 42)\n",
      "111780.04703178197\n",
      "(34754, 43)\n",
      "110388.27314777276\n",
      "(34754, 35)\n",
      "110379.84359161655\n",
      "(34754, 40)\n",
      "112111.26679452838\n",
      "(34754, 34)\n",
      "110105.77595107422\n",
      "(34754, 38)\n",
      "112997.05747536839\n",
      "(34754, 36)\n",
      "112207.64695072212\n",
      "(34754, 35)\n",
      "109437.0756162046\n",
      "(34754, 34)\n",
      "110881.20320148909\n",
      "(34754, 33)\n",
      "112381.88743841778\n",
      "(34754, 45)\n",
      "109117.05100793291\n",
      "(34754, 28)\n",
      "111195.23375374374\n",
      "(34754, 43)\n",
      "113014.64663631353\n",
      "(34754, 39)\n",
      "112122.61976619209\n",
      "(34754, 42)\n",
      "110201.8121453957\n",
      "(34754, 40)\n",
      "112363.91169394508\n",
      "(34754, 36)\n",
      "110344.15882041343\n",
      "(34754, 41)\n",
      "113099.9820514636\n",
      "(34754, 46)\n",
      "111962.64062887337\n",
      "(34754, 32)\n",
      "115166.27826418939\n",
      "(34754, 32)\n",
      "112708.04413050413\n",
      "(34754, 43)\n",
      "111029.19700442362\n",
      "(34754, 42)\n",
      "114885.98931512873\n",
      "(34754, 42)\n",
      "110383.52738315736\n",
      "(34754, 40)\n",
      "109190.65232979793\n",
      "(34754, 42)\n",
      "112103.93003789193\n",
      "(34754, 36)\n",
      "114545.67522438517\n",
      "(34754, 39)\n",
      "110164.95739120989\n",
      "(34754, 36)\n",
      "113891.50801806936\n",
      "(34754, 36)\n",
      "112240.53388019293\n",
      "(34754, 42)\n",
      "110931.49520702955\n",
      "(34754, 36)\n",
      "110861.98918886365\n",
      "(34754, 43)\n",
      "111442.93653289622\n",
      "(34754, 39)\n",
      "112224.33250273988\n",
      "(34754, 38)\n",
      "110019.3161633765\n",
      "(34754, 38)\n",
      "112941.1792923946\n",
      "(34754, 38)\n",
      "109797.34104763238\n",
      "(34754, 40)\n",
      "110773.04855764074\n",
      "(34754, 36)\n",
      "112050.58229574708\n",
      "(34754, 32)\n",
      "111091.0618546727\n",
      "(34754, 44)\n",
      "113117.11145800404\n",
      "(34754, 31)\n",
      "113770.43080012893\n",
      "(34754, 43)\n",
      "110015.37560945869\n",
      "(34754, 33)\n",
      "110940.93847558537\n",
      "(34754, 40)\n",
      "110719.59093686387\n",
      "(34754, 40)\n",
      "110508.83437837135\n",
      "(34754, 47)\n",
      "112202.22564248827\n",
      "(34754, 41)\n",
      "111103.3669091461\n",
      "(34754, 40)\n",
      "111372.39366077636\n",
      "(34754, 48)\n",
      "112053.03485624805\n",
      "(34754, 44)\n",
      "110041.98287629853\n",
      "(34754, 39)\n",
      "109750.84114340972\n",
      "(34754, 39)\n",
      "112697.72825332063\n",
      "(34754, 43)\n",
      "113463.31314128696\n",
      "(34754, 44)\n",
      "112742.60510582708\n",
      "(34754, 36)\n",
      "109394.62958033016\n",
      "(34754, 42)\n",
      "109954.93420286058\n",
      "(34754, 35)\n",
      "110642.639185396\n",
      "(34754, 45)\n",
      "110536.160927645\n",
      "(34754, 42)\n",
      "110462.19132871508\n",
      "(34754, 40)\n",
      "109719.98995350802\n",
      "(34754, 45)\n",
      "111876.32360290524\n",
      "(34754, 45)\n",
      "110122.22361086226\n",
      "(34754, 39)\n",
      "111054.1317105828\n",
      "(34754, 41)\n",
      "111877.74899144226\n",
      "(34754, 44)\n",
      "110858.9650799943\n",
      "(34754, 41)\n",
      "110923.63785038189\n",
      "(34754, 42)\n",
      "110315.62890733873\n",
      "(34754, 42)\n",
      "109506.99698017571\n",
      "(34754, 41)\n",
      "111383.4912017864\n",
      "(34754, 46)\n",
      "113024.82380001844\n",
      "(34754, 50)\n",
      "110729.67772005481\n",
      "(34754, 43)\n",
      "111262.77832585342\n",
      "(34754, 40)\n",
      "110076.0381711945\n",
      "(34754, 39)\n",
      "110488.13000604603\n",
      "(34754, 33)\n",
      "110084.95234830372\n",
      "(34754, 45)\n",
      "108726.72859562901\n",
      "(34754, 41)\n",
      "110659.90036541627\n",
      "(34754, 37)\n",
      "111988.54002234268\n",
      "(34754, 30)\n",
      "114197.66876387672\n",
      "(34754, 35)\n",
      "109876.24149858569\n",
      "(34754, 44)\n",
      "113141.10848913754\n",
      "(34754, 42)\n",
      "111175.25402513926\n",
      "(34754, 37)\n",
      "110477.5934661513\n",
      "(34754, 30)\n",
      "113053.9796544828\n",
      "(34754, 31)\n",
      "113455.48154084943\n",
      "(34754, 38)\n",
      "110011.19144617653\n",
      "(34754, 42)\n",
      "111397.8523163766\n",
      "(34754, 38)\n",
      "110890.10585898894\n",
      "(34754, 33)\n",
      "113939.76841337586\n",
      "(34754, 37)\n",
      "112569.52925382437\n",
      "(34754, 42)\n",
      "113208.59883059106\n",
      "(34754, 39)\n",
      "112613.62251556572\n",
      "(34754, 36)\n",
      "109806.20272402636\n",
      "(34754, 41)\n",
      "111050.17733961111\n",
      "(34754, 36)\n",
      "111773.82511696595\n",
      "(34754, 44)\n",
      "111225.19062978629\n",
      "(34754, 34)\n",
      "112244.6325501267\n",
      "(34754, 45)\n",
      "109484.30531603235\n",
      "(34754, 38)\n",
      "113922.73907714195\n",
      "(34754, 42)\n",
      "111043.07229436832\n",
      "(34754, 30)\n",
      "114477.52126800128\n",
      "(34754, 39)\n",
      "111488.53740361764\n",
      "(34754, 38)\n",
      "109772.79947047627\n",
      "(34754, 45)\n",
      "111710.07300363945\n",
      "(34754, 44)\n",
      "110415.76745659998\n",
      "(34754, 40)\n",
      "111430.42201382542\n",
      "(34754, 40)\n",
      "111390.99625011224\n",
      "(34754, 45)\n",
      "112922.30381202136\n",
      "(34754, 40)\n",
      "110183.82828193267\n",
      "(34754, 37)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109787.86984053523\n",
      "(34754, 42)\n",
      "111993.76387168879\n",
      "(34754, 41)\n",
      "113355.28527036773\n",
      "(34754, 41)\n",
      "113001.62535101932\n",
      "(34754, 40)\n",
      "114518.0700256917\n",
      "(34754, 35)\n",
      "111820.58908339542\n",
      "(34754, 44)\n",
      "113355.65912847666\n",
      "(34754, 35)\n",
      "114541.87352994818\n",
      "(34754, 38)\n",
      "111540.94965461026\n",
      "(34754, 37)\n",
      "113252.20037322897\n",
      "(34754, 43)\n",
      "111395.01341213714\n",
      "(34754, 33)\n",
      "110087.82936183465\n",
      "(34754, 44)\n",
      "110450.80654602246\n",
      "(34754, 36)\n",
      "112333.14561226501\n",
      "(34754, 45)\n",
      "110701.51597516095\n",
      "(34754, 37)\n",
      "112478.97497721628\n",
      "(34754, 39)\n",
      "111037.49628006555\n",
      "(34754, 36)\n",
      "110857.69357327247\n",
      "(34754, 43)\n",
      "111690.94629589826\n",
      "(34754, 41)\n",
      "111711.0814767352\n",
      "(34754, 35)\n",
      "111284.19062944109\n",
      "(34754, 38)\n",
      "111271.45019510816\n",
      "(34754, 39)\n",
      "111813.61557090358\n",
      "(34754, 43)\n",
      "113147.41851040191\n",
      "(34754, 42)\n",
      "111214.55343818663\n",
      "(34754, 41)\n",
      "112948.97107170592\n",
      "(34754, 41)\n",
      "110349.49783336955\n",
      "(34754, 39)\n",
      "112739.45455165379\n",
      "(34754, 27)\n",
      "112923.14229406134\n",
      "(34754, 36)\n",
      "112193.74139260643\n",
      "(34754, 41)\n",
      "114105.51868777913\n",
      "(34754, 43)\n",
      "111949.24121066934\n",
      "(34754, 41)\n",
      "112226.4755371491\n",
      "(34754, 39)\n",
      "110312.01825238603\n",
      "(34754, 45)\n",
      "113160.21681081208\n",
      "(34754, 40)\n",
      "110149.42588692807\n",
      "(34754, 31)\n",
      "110734.71355116359\n",
      "(34754, 38)\n",
      "111158.26815773823\n",
      "(34754, 40)\n",
      "112370.05315044853\n",
      "(34754, 41)\n",
      "111397.9658331765\n",
      "(34754, 31)\n",
      "111516.67075036676\n",
      "(34754, 41)\n",
      "113401.77227783551\n",
      "(34754, 40)\n",
      "112456.78987622363\n",
      "(34754, 32)\n",
      "109887.2860678656\n",
      "(34754, 40)\n",
      "115334.3250390199\n",
      "(34754, 50)\n",
      "111246.11423502766\n",
      "(34754, 39)\n",
      "111811.62503305098\n",
      "(34754, 37)\n",
      "109600.78981919232\n",
      "(34754, 34)\n",
      "110420.59018664827\n",
      "(34754, 42)\n",
      "113907.48045003123\n",
      "(34754, 38)\n",
      "110415.07472496285\n",
      "(34754, 39)\n",
      "111653.33882490835\n",
      "(34754, 39)\n",
      "111044.85208263136\n",
      "(34754, 36)\n",
      "113100.40143814014\n",
      "(34754, 36)\n",
      "110791.89357396118\n",
      "(34754, 48)\n",
      "113201.21133578049\n",
      "(34754, 43)\n",
      "110643.96755947621\n",
      "(34754, 39)\n",
      "110810.51873655076\n",
      "(34754, 36)\n",
      "110268.78472270278\n",
      "(34754, 47)\n",
      "110678.80750385066\n",
      "(34754, 45)\n",
      "111963.33779838122\n",
      "(34754, 40)\n",
      "115053.68977645303\n",
      "(34754, 41)\n",
      "114847.49688497413\n",
      "(34754, 41)\n",
      "112352.67981066993\n",
      "(34754, 46)\n",
      "111401.77735864231\n",
      "(34754, 40)\n",
      "112848.69865931524\n",
      "(34754, 39)\n",
      "114056.57830798974\n",
      "(34754, 37)\n",
      "111181.50737744676\n",
      "(34754, 48)\n",
      "110467.68271725252\n",
      "(34754, 34)\n",
      "113025.6453639811\n",
      "(34754, 41)\n",
      "110772.50445048112\n",
      "(34754, 38)\n",
      "112253.22710248452\n",
      "(34754, 38)\n",
      "113546.5650918637\n",
      "(34754, 43)\n",
      "112241.65878516047\n",
      "(34754, 38)\n",
      "110819.7538675414\n",
      "(34754, 45)\n",
      "111876.57768074355\n",
      "(34754, 42)\n",
      "111905.2693030249\n",
      "(34754, 44)\n",
      "111248.47149668408\n",
      "(34754, 38)\n",
      "114077.80016949582\n",
      "(34754, 38)\n",
      "110823.10084176232\n",
      "(34754, 38)\n",
      "111874.83397795275\n",
      "(34754, 37)\n",
      "110174.58282865181\n",
      "(34754, 39)\n",
      "113214.52176103593\n",
      "(34754, 38)\n",
      "114204.38810103486\n",
      "(34754, 32)\n",
      "110665.37664414747\n",
      "(34754, 46)\n",
      "111148.89102631064\n",
      "(34754, 46)\n",
      "112673.15811157503\n",
      "(34754, 40)\n",
      "112516.77173539872\n",
      "(34754, 44)\n",
      "110621.58352138505\n",
      "(34754, 36)\n",
      "110688.0841091923\n",
      "(34754, 44)\n",
      "110694.40528859517\n",
      "(34754, 38)\n",
      "111109.34821862484\n",
      "(34754, 35)\n",
      "111314.48128089528\n",
      "(34754, 39)\n",
      "112240.41993380201\n",
      "(34754, 40)\n",
      "109623.449759209\n",
      "(34754, 43)\n",
      "109729.75428539929\n",
      "(34754, 44)\n",
      "111962.34189286517\n",
      "(34754, 32)\n",
      "114770.77884594683\n",
      "(34754, 41)\n",
      "112067.91820717101\n",
      "(34754, 45)\n",
      "111475.23462574072\n",
      "(34754, 39)\n",
      "108987.99305934856\n",
      "(34754, 41)\n",
      "111394.49101084507\n",
      "(34754, 38)\n",
      "113412.81284571698\n",
      "(34754, 40)\n",
      "111863.05718430302\n",
      "(34754, 39)\n",
      "111134.64704836273\n",
      "(34754, 42)\n",
      "111534.93660771262\n",
      "(34754, 50)\n",
      "110737.01052157057\n",
      "(34754, 44)\n",
      "110809.75595194873\n",
      "(34754, 41)\n",
      "111858.08687180278\n",
      "(34754, 43)\n",
      "110079.70368136444\n",
      "(34754, 37)\n",
      "113510.38994107312\n",
      "(34754, 39)\n",
      "109165.27199297801\n",
      "(34754, 36)\n",
      "110871.81663019452\n",
      "(34754, 38)\n",
      "111051.18343109479\n",
      "(34754, 41)\n",
      "111427.90304297597\n",
      "(34754, 42)\n",
      "113050.45983695635\n",
      "(34754, 43)\n",
      "113561.62142362221\n",
      "(34754, 37)\n",
      "110191.53139270694\n",
      "(34754, 39)\n",
      "112185.51351311897\n",
      "(34754, 36)\n",
      "114256.18785575761\n",
      "(34754, 42)\n",
      "109490.11546094637\n",
      "(34754, 39)\n",
      "111552.55125940253\n",
      "(34754, 39)\n",
      "112840.60687988525\n",
      "(34754, 34)\n",
      "113086.78012737962\n",
      "(34754, 36)\n",
      "111171.20114595137\n",
      "(34754, 49)\n",
      "111151.91040530239\n",
      "(34754, 33)\n",
      "114749.8797903829\n",
      "(34754, 46)\n",
      "110489.10188276433\n",
      "(34754, 41)\n",
      "110613.37879877305\n",
      "(34754, 39)\n",
      "110825.69324384333\n",
      "(34754, 43)\n",
      "114124.16988753533\n",
      "(34754, 43)\n",
      "111625.49939077237\n",
      "(34754, 44)\n",
      "110800.80251340267\n",
      "(34754, 37)\n",
      "112648.30426428006\n",
      "(34754, 39)\n",
      "110295.98331273692\n",
      "(34754, 42)\n",
      "112529.95806971058\n",
      "(34754, 40)\n",
      "111912.19024166581\n",
      "(34754, 38)\n",
      "108551.6690517785\n",
      "(34754, 36)\n",
      "112248.81032857976\n",
      "(34754, 32)\n",
      "112649.20490942105\n",
      "(34754, 49)\n",
      "110213.60145789018\n",
      "(34754, 39)\n",
      "110044.8840695607\n",
      "(34754, 40)\n",
      "113157.13593119988\n",
      "(34754, 35)\n",
      "113418.63628764258\n",
      "(34754, 36)\n",
      "109275.83064976001\n",
      "(34754, 43)\n",
      "113517.87969795319\n",
      "(34754, 33)\n",
      "112060.72544864373\n",
      "(34754, 47)\n",
      "110680.5002230217\n",
      "(34754, 44)\n",
      "113895.5472703981\n",
      "(34754, 34)\n",
      "110734.49269467346\n",
      "(34754, 43)\n",
      "110940.27936079871\n",
      "(34754, 40)\n",
      "113640.78437764266\n",
      "(34754, 45)\n",
      "110997.8051010877\n",
      "(34754, 33)\n",
      "114771.15039028286\n",
      "(34754, 36)\n",
      "111690.5643476963\n",
      "(34754, 46)\n",
      "112730.45331240763\n",
      "(34754, 43)\n",
      "110982.44073882035\n",
      "(34754, 39)\n",
      "112757.16908842746\n",
      "(34754, 42)\n",
      "111823.72144759237\n",
      "(34754, 42)\n",
      "112880.24014946877\n",
      "(34754, 32)\n",
      "111213.3701459219\n",
      "(34754, 35)\n",
      "110168.43200253138\n",
      "(34754, 37)\n",
      "109323.24662744769\n",
      "(34754, 37)\n",
      "110999.36334967593\n",
      "(34754, 44)\n",
      "110654.41270769257\n",
      "(34754, 43)\n",
      "110198.39944666263\n",
      "(34754, 38)\n",
      "111336.76540862654\n",
      "(34754, 43)\n",
      "111633.203744138\n",
      "(34754, 38)\n",
      "111625.73336356365\n",
      "(34754, 36)\n",
      "112370.9028418461\n",
      "(34754, 40)\n",
      "114362.11402359766\n",
      "(34754, 35)\n",
      "112862.56097172864\n",
      "(34754, 36)\n",
      "112458.53965850578\n",
      "(34754, 41)\n",
      "110804.9179930572\n",
      "(34754, 39)\n",
      "110201.57340453268\n",
      "(34754, 34)\n",
      "111997.74215673043\n",
      "(34754, 43)\n",
      "111692.69973778505\n",
      "(34754, 35)\n",
      "111721.63101513407\n",
      "(34754, 47)\n",
      "111110.74528522266\n",
      "(34754, 38)\n",
      "112424.31636248526\n",
      "(34754, 43)\n",
      "112826.70257026755\n",
      "(34754, 40)\n",
      "108906.27503661189\n",
      "(34754, 40)\n",
      "111988.28345617418\n",
      "(34754, 38)\n",
      "113934.30750229454\n",
      "(34754, 42)\n",
      "111451.73592545814\n",
      "(34754, 42)\n",
      "113632.96832495592\n",
      "(34754, 37)\n",
      "113338.43595841601\n",
      "(34754, 43)\n",
      "109250.86662785742\n",
      "(34754, 38)\n",
      "110097.41932990303\n",
      "(34754, 40)\n",
      "112227.36710149898\n",
      "(34754, 35)\n",
      "111591.18023677634\n",
      "(34754, 40)\n",
      "110783.35739344622\n",
      "(34754, 38)\n",
      "112997.8654922779\n",
      "(34754, 34)\n",
      "108801.8981341672\n",
      "(34754, 46)\n",
      "109120.99090049599\n",
      "(34754, 38)\n",
      "111215.84242461646\n",
      "(34754, 40)\n",
      "109281.3116885793\n",
      "(34754, 37)\n",
      "110703.37157099825\n",
      "(34754, 37)\n",
      "109160.70794831961\n",
      "(34754, 38)\n",
      "111812.8013525573\n",
      "(34754, 39)\n",
      "112566.80894364521\n",
      "(34754, 36)\n",
      "114106.45358567993\n",
      "(34754, 40)\n",
      "110733.95022670223\n",
      "(34754, 34)\n",
      "111415.39226866257\n",
      "(34754, 38)\n",
      "109906.97235747574\n",
      "(34754, 38)\n",
      "110976.04562534436\n",
      "(34754, 36)\n",
      "112621.73578084321\n",
      "(34754, 38)\n",
      "112988.61423316809\n",
      "(34754, 36)\n",
      "111584.22456213327\n",
      "(34754, 40)\n",
      "111674.1491879135\n",
      "(34754, 45)\n",
      "110216.84049899259\n",
      "(34754, 35)\n",
      "111830.89190230193\n",
      "(34754, 42)\n",
      "113358.24554072127\n",
      "(34754, 36)\n",
      "111604.59343259249\n",
      "(34754, 39)\n",
      "110408.89048570557\n",
      "(34754, 36)\n",
      "109589.91663228998\n",
      "(34754, 41)\n",
      "111986.05770595597\n",
      "(34754, 39)\n",
      "112102.65011792126\n",
      "(34754, 44)\n",
      "111185.26497384734\n",
      "(34754, 40)\n",
      "111722.53294154124\n",
      "(34754, 43)\n",
      "111944.21135974252\n",
      "(34754, 40)\n",
      "111630.16371303322\n",
      "(34754, 41)\n",
      "111390.02294279708\n",
      "(34754, 47)\n",
      "111022.5252309168\n",
      "(34754, 43)\n",
      "112847.9899593326\n",
      "(34754, 42)\n",
      "109187.36195121711\n",
      "(34754, 39)\n",
      "112160.84711333776\n",
      "(34754, 41)\n",
      "111871.04441525288\n",
      "(34754, 49)\n",
      "110102.0534500767\n",
      "(34754, 42)\n",
      "113300.75166275034\n",
      "(34754, 40)\n",
      "111732.34384469314\n",
      "(34754, 40)\n",
      "110794.27470816803\n",
      "(34754, 34)\n",
      "111239.91219641676\n",
      "(34754, 46)\n",
      "111293.92368366924\n",
      "(34754, 40)\n",
      "109964.07098350712\n",
      "(34754, 45)\n",
      "111472.15519180623\n",
      "(34754, 45)\n",
      "109930.23577515884\n",
      "(34754, 39)\n",
      "112537.11320240003\n",
      "(34754, 45)\n",
      "114248.85359902533\n",
      "(34754, 38)\n",
      "110831.69647264735\n",
      "(34754, 27)\n",
      "112116.82855724447\n",
      "(34754, 45)\n",
      "112172.84699819851\n",
      "(34754, 45)\n",
      "110240.97879227134\n",
      "(34754, 41)\n",
      "110030.5372304823\n",
      "(34754, 41)\n",
      "114456.46502792623\n",
      "(34754, 38)\n",
      "113783.62553321362\n",
      "(34754, 43)\n",
      "110163.18008309497\n",
      "(34754, 42)\n",
      "112921.97891747938\n",
      "(34754, 39)\n",
      "112610.71940140334\n",
      "(34754, 38)\n",
      "109914.42576845204\n",
      "(34754, 37)\n",
      "113890.74937433445\n",
      "(34754, 41)\n",
      "109511.70652548215\n",
      "(34754, 36)\n",
      "111161.85008037128\n",
      "(34754, 40)\n",
      "109449.48695552701\n",
      "(34754, 38)\n",
      "111504.9869101651\n",
      "(34754, 36)\n",
      "113213.19381318096\n",
      "(34754, 39)\n",
      "111249.80106448506\n",
      "(34754, 47)\n",
      "113453.79152643679\n",
      "(34754, 39)\n",
      "112662.70094709747\n",
      "(34754, 48)\n",
      "111849.37516428842\n",
      "(34754, 42)\n",
      "110242.27595352259\n",
      "(34754, 45)\n",
      "112871.65858664043\n",
      "(34754, 42)\n",
      "112048.82770456414\n",
      "(34754, 41)\n",
      "110041.66360198964\n",
      "(34754, 48)\n",
      "112299.35582778392\n",
      "(34754, 39)\n",
      "112705.74602122654\n",
      "(34754, 39)\n",
      "112790.16113149328\n",
      "(34754, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109354.28288465759\n",
      "(34754, 48)\n",
      "110300.97035825999\n",
      "(34754, 39)\n",
      "113278.91431075576\n",
      "(34754, 39)\n",
      "108985.88261259832\n",
      "(34754, 47)\n",
      "111576.30440033118\n",
      "(34754, 40)\n",
      "110485.94979928588\n",
      "(34754, 30)\n",
      "113717.8921440863\n",
      "(34754, 38)\n",
      "109458.66537397476\n",
      "(34754, 42)\n",
      "110568.55055995744\n",
      "(34754, 46)\n",
      "111916.95523964165\n",
      "(34754, 33)\n",
      "110630.64526496692\n",
      "(34754, 38)\n",
      "112675.6570874239\n",
      "(34754, 44)\n",
      "112124.80446823979\n",
      "(34754, 40)\n",
      "113328.03357935454\n",
      "(34754, 42)\n",
      "112504.71678215497\n",
      "(34754, 34)\n",
      "113382.2938732568\n",
      "(34754, 42)\n",
      "112693.1276003514\n",
      "(34754, 41)\n",
      "112430.22737699065\n",
      "(34754, 34)\n",
      "111081.44751694691\n",
      "(34754, 36)\n",
      "111087.70005170937\n",
      "(34754, 38)\n",
      "114565.5182125271\n",
      "(34754, 36)\n",
      "113102.44681467477\n",
      "(34754, 42)\n",
      "114348.79200422214\n",
      "(34754, 43)\n",
      "109180.24134308033\n",
      "(34754, 50)\n",
      "109961.47812737647\n",
      "(34754, 32)\n",
      "112034.31227054738\n",
      "(34754, 41)\n",
      "111911.29649574516\n",
      "(34754, 33)\n",
      "112155.91039449554\n",
      "(34754, 30)\n",
      "110484.9266482595\n",
      "(34754, 42)\n",
      "110246.65814893403\n",
      "(34754, 35)\n",
      "113312.20908848588\n",
      "(34754, 40)\n",
      "113567.33321438126\n",
      "(34754, 40)\n",
      "114105.74429006096\n",
      "(34754, 46)\n",
      "110654.35339168004\n",
      "(34754, 41)\n",
      "110152.86589703252\n",
      "(34754, 46)\n",
      "108577.86329888702\n",
      "(34754, 42)\n",
      "110120.18212138592\n",
      "(34754, 39)\n",
      "110095.58947631926\n",
      "(34754, 41)\n",
      "113005.04623168182\n",
      "(34754, 37)\n",
      "114739.70234158658\n",
      "(34754, 39)\n",
      "112429.1834379976\n",
      "(34754, 35)\n",
      "112709.79013019866\n",
      "(34754, 33)\n",
      "110911.8288466087\n",
      "(34754, 40)\n",
      "111758.40382238702\n",
      "(34754, 41)\n",
      "112860.59682246036\n",
      "(34754, 38)\n",
      "110657.36559993135\n",
      "(34754, 42)\n",
      "110012.82334896157\n",
      "(34754, 40)\n",
      "113567.33690937153\n",
      "(34754, 35)\n",
      "109023.33664052257\n",
      "(34754, 44)\n",
      "111458.0583049755\n",
      "(34754, 48)\n",
      "112034.16980252965\n",
      "(34754, 41)\n",
      "113234.07600843423\n",
      "(34754, 35)\n",
      "112053.54638332047\n",
      "(34754, 45)\n",
      "110195.58212782418\n",
      "(34754, 41)\n",
      "111552.18683618565\n",
      "(34754, 42)\n",
      "110971.59472489373\n",
      "(34754, 40)\n",
      "111499.44620634564\n",
      "(34754, 43)\n",
      "111247.52725322191\n",
      "(34754, 34)\n",
      "115142.67122323248\n",
      "(34754, 36)\n",
      "110046.96335750069\n",
      "(34754, 42)\n",
      "112037.94599177256\n",
      "(34754, 42)\n",
      "110709.08112532097\n",
      "(34754, 40)\n",
      "111372.62152202205\n",
      "(34754, 40)\n",
      "114512.84964719611\n",
      "(34754, 42)\n",
      "110274.3911800177\n",
      "(34754, 37)\n",
      "108955.83419124834\n",
      "(34754, 32)\n",
      "112330.75540254795\n",
      "(34754, 41)\n",
      "111140.98864148051\n",
      "(34754, 32)\n",
      "113016.12760957416\n",
      "(34754, 40)\n",
      "113654.42704818935\n",
      "(34754, 45)\n",
      "110320.61373040077\n",
      "(34754, 36)\n",
      "111492.86557940386\n",
      "(34754, 44)\n",
      "110492.81291929513\n",
      "(34754, 36)\n",
      "109205.81072258505\n",
      "(34754, 38)\n",
      "109758.94675651197\n",
      "(34754, 38)\n",
      "111350.1393209258\n",
      "(34754, 53)\n",
      "109009.43783872198\n",
      "(34754, 46)\n",
      "110467.76517761049\n",
      "(34754, 35)\n",
      "113115.25619828406\n",
      "(34754, 35)\n",
      "113599.7408650944\n",
      "(34754, 41)\n",
      "111839.16412518556\n",
      "(34754, 48)\n",
      "111259.50509843233\n",
      "(34754, 46)\n",
      "111166.45022872725\n",
      "(34754, 43)\n",
      "109583.03668634394\n",
      "(34754, 39)\n",
      "110881.79745562858\n",
      "(34754, 33)\n",
      "112672.73730509011\n",
      "(34754, 39)\n",
      "114297.58685696486\n",
      "(34754, 36)\n",
      "109885.18125109097\n",
      "(34754, 38)\n",
      "113125.80954371009\n",
      "(34754, 37)\n",
      "111539.72925630868\n",
      "(34754, 38)\n",
      "112358.11630531366\n",
      "(34754, 46)\n",
      "113102.62792717885\n",
      "(34754, 43)\n",
      "111000.62908855108\n",
      "(34754, 45)\n",
      "112585.21158266661\n",
      "(34754, 37)\n",
      "111191.66833560423\n",
      "(34754, 42)\n",
      "112339.73069734663\n",
      "(34754, 45)\n",
      "111643.82803070065\n",
      "(34754, 43)\n",
      "113290.67487425206\n",
      "(34754, 40)\n",
      "109524.32229958843\n",
      "(34754, 45)\n",
      "110303.86094128534\n",
      "(34754, 48)\n",
      "110798.03592796758\n",
      "(34754, 42)\n",
      "110030.4068525954\n",
      "(34754, 36)\n",
      "112688.43495049376\n",
      "(34754, 46)\n",
      "110604.03472267685\n",
      "(34754, 40)\n",
      "111925.1470676578\n",
      "(34754, 42)\n",
      "113458.1486988545\n",
      "(34754, 48)\n",
      "111490.73166917094\n",
      "(34754, 39)\n",
      "109190.9986620895\n",
      "(34754, 42)\n",
      "109686.28801954689\n",
      "(34754, 47)\n",
      "114181.4351797233\n",
      "(34754, 40)\n",
      "113837.55356469264\n",
      "(34754, 40)\n",
      "109412.95457319103\n",
      "(34754, 34)\n",
      "113276.75084473302\n",
      "(34754, 41)\n",
      "110296.68990178981\n",
      "(34754, 45)\n",
      "108477.62454973707\n",
      "(34754, 36)\n",
      "113596.89184968585\n",
      "(34754, 41)\n",
      "112671.4409581334\n",
      "(34754, 38)\n",
      "109997.9320274213\n",
      "(34754, 42)\n",
      "111255.13077617824\n",
      "(34754, 47)\n",
      "111985.34241313954\n",
      "(34754, 40)\n",
      "110506.13015338\n",
      "(34754, 40)\n",
      "111455.65118146891\n",
      "(34754, 37)\n",
      "114383.43482791379\n",
      "(34754, 33)\n",
      "111991.1233282383\n",
      "(34754, 38)\n",
      "114456.56960479642\n",
      "(34754, 42)\n",
      "112812.33743454002\n",
      "(34754, 39)\n",
      "109934.31900339577\n",
      "(34754, 37)\n",
      "113122.63455547302\n",
      "(34754, 39)\n",
      "111960.57892928734\n",
      "(34754, 54)\n",
      "113140.86019435932\n",
      "(34754, 42)\n",
      "112017.47098484602\n",
      "(34754, 39)\n",
      "115202.88444430174\n",
      "(34754, 47)\n",
      "111748.57033310294\n",
      "(34754, 42)\n",
      "111033.19954825733\n",
      "(34754, 43)\n",
      "112652.57153071619\n",
      "(34754, 34)\n",
      "109618.61780898293\n",
      "(34754, 45)\n",
      "111931.10288473083\n",
      "(34754, 41)\n",
      "112966.15705603096\n",
      "(34754, 41)\n",
      "111701.22694646558\n",
      "(34754, 38)\n",
      "112056.86211463858\n",
      "(34754, 41)\n",
      "111534.54475156717\n",
      "(34754, 36)\n",
      "110422.84215234825\n",
      "(34754, 38)\n",
      "114673.71268694474\n",
      "(34754, 35)\n",
      "111052.6031638349\n",
      "(34754, 39)\n",
      "114183.35745080307\n",
      "(34754, 45)\n",
      "111021.08977886346\n",
      "(34754, 39)\n",
      "110402.79898415512\n",
      "(34754, 36)\n",
      "112218.78630524645\n",
      "(34754, 44)\n",
      "110224.48525391145\n",
      "(34754, 35)\n",
      "112052.5458226779\n",
      "(34754, 39)\n",
      "110341.32048923757\n",
      "(34754, 45)\n",
      "113424.84593882349\n",
      "(34754, 50)\n",
      "110551.96284965832\n",
      "(34754, 42)\n",
      "113712.59464819827\n",
      "(34754, 42)\n",
      "111786.93760811453\n",
      "(34754, 39)\n",
      "111537.73821757943\n",
      "(34754, 43)\n",
      "111485.39690196031\n",
      "(34754, 40)\n",
      "112313.88645944012\n",
      "(34754, 36)\n",
      "113789.52918887016\n",
      "(34754, 44)\n",
      "110208.36784540793\n",
      "(34754, 36)\n",
      "111201.7421087746\n",
      "(34754, 39)\n",
      "112004.98024000152\n",
      "(34754, 36)\n",
      "111346.82099663944\n",
      "(34754, 34)\n",
      "110216.66782051067\n",
      "(34754, 42)\n",
      "111423.79134856726\n",
      "(34754, 46)\n",
      "110341.88215666286\n",
      "(34754, 44)\n",
      "112864.36047876808\n",
      "(34754, 38)\n",
      "111084.51155116643\n",
      "(34754, 36)\n",
      "113117.56348362681\n",
      "(34754, 39)\n",
      "111611.83809564557\n",
      "(34754, 41)\n",
      "111894.32207892745\n",
      "(34754, 32)\n",
      "114224.98273286612\n",
      "(34754, 41)\n",
      "112449.0291350232\n",
      "(34754, 40)\n",
      "111700.31171683666\n",
      "(34754, 44)\n",
      "110455.05675470087\n",
      "(34754, 26)\n",
      "112987.89610261061\n",
      "(34754, 44)\n",
      "111526.86202185368\n",
      "(34754, 43)\n",
      "111392.39212201595\n",
      "(34754, 43)\n",
      "110433.19127138062\n",
      "(34754, 45)\n",
      "110528.05526823767\n",
      "(34754, 35)\n",
      "114562.8130341775\n",
      "(34754, 38)\n",
      "111227.44814098829\n",
      "(34754, 43)\n",
      "109050.11672243908\n",
      "(34754, 41)\n",
      "112443.05958605853\n",
      "(34754, 36)\n",
      "110627.6168819008\n",
      "(34754, 41)\n",
      "110969.07174030432\n",
      "(34754, 44)\n",
      "111405.8445652788\n",
      "(34754, 40)\n",
      "111560.92580877298\n",
      "(34754, 42)\n",
      "111618.76577878332\n",
      "(34754, 40)\n",
      "110838.9524915239\n",
      "(34754, 43)\n",
      "111581.0589586759\n",
      "(34754, 39)\n",
      "109625.99388110371\n",
      "(34754, 46)\n",
      "111652.76328741052\n",
      "(34754, 32)\n",
      "111201.50248009649\n",
      "(34754, 43)\n",
      "110943.84918278713\n",
      "(34754, 34)\n",
      "109702.83449749784\n",
      "(34754, 36)\n",
      "112276.04973884251\n",
      "(34754, 39)\n",
      "112177.51856976829\n",
      "(34754, 38)\n",
      "110416.02987651166\n",
      "(34754, 49)\n",
      "110731.64264395127\n",
      "(34754, 46)\n",
      "111874.26969559463\n",
      "(34754, 33)\n",
      "111803.08701217391\n",
      "(34754, 43)\n",
      "114462.56016493979\n",
      "(34754, 30)\n",
      "113433.36874791858\n",
      "(34754, 46)\n",
      "113851.5354539573\n",
      "(34754, 40)\n",
      "110935.70954873893\n",
      "(34754, 38)\n",
      "110899.70072751888\n",
      "(34754, 44)\n",
      "109869.78253272384\n",
      "(34754, 38)\n",
      "111642.858550249\n",
      "(34754, 36)\n",
      "111771.44493491559\n",
      "(34754, 43)\n",
      "109694.76506193662\n",
      "(34754, 40)\n",
      "113405.79796027752\n",
      "(34754, 32)\n",
      "110582.28172187285\n",
      "(34754, 36)\n",
      "110542.7576378407\n",
      "(34754, 38)\n",
      "111617.35636387666\n",
      "(34754, 38)\n",
      "110195.12505325367\n",
      "(34754, 41)\n",
      "110511.39920093253\n",
      "(34754, 40)\n",
      "110334.33267466423\n",
      "(34754, 37)\n",
      "112861.42456478688\n",
      "(34754, 40)\n",
      "110882.550785852\n",
      "(34754, 42)\n",
      "110737.2265841743\n",
      "(34754, 36)\n",
      "110911.51449055494\n",
      "(34754, 35)\n",
      "111676.68560774226\n",
      "(34754, 41)\n",
      "111700.41626370132\n",
      "(34754, 42)\n",
      "111604.43783518983\n",
      "(34754, 39)\n",
      "110472.05548411763\n",
      "(34754, 38)\n",
      "111142.66357013253\n",
      "(34754, 38)\n",
      "110587.7386607611\n",
      "(34754, 45)\n",
      "109824.83458730434\n",
      "(34754, 40)\n",
      "110646.32599846767\n",
      "(34754, 44)\n",
      "111522.43395288844\n",
      "(34754, 44)\n",
      "109029.12203450162\n",
      "(34754, 42)\n",
      "112439.52794139483\n",
      "(34754, 27)\n",
      "114810.85697876151\n",
      "(34754, 38)\n",
      "110765.39047093963\n",
      "(34754, 45)\n",
      "112679.94732508628\n",
      "(34754, 46)\n",
      "109771.8897538113\n",
      "(34754, 46)\n",
      "109867.088896069\n",
      "(34754, 36)\n",
      "110582.26895596912\n",
      "(34754, 39)\n",
      "111397.18805207917\n",
      "(34754, 39)\n",
      "113670.89779538313\n",
      "(34754, 35)\n",
      "111585.57186135241\n",
      "(34754, 44)\n",
      "109670.06126035079\n",
      "(34754, 43)\n",
      "110527.90584187488\n",
      "(34754, 41)\n",
      "110611.85830236916\n",
      "(34754, 44)\n",
      "109617.32376605549\n",
      "(34754, 40)\n",
      "112025.05301257009\n",
      "(34754, 36)\n",
      "111547.3671032349\n",
      "(34754, 32)\n",
      "113759.27837983795\n",
      "(34754, 46)\n",
      "110941.467969506\n",
      "(34754, 34)\n",
      "110911.2073310933\n",
      "(34754, 45)\n",
      "109987.48204923588\n",
      "(34754, 41)\n",
      "110528.79699907318\n",
      "(34754, 38)\n",
      "109492.72432790074\n",
      "(34754, 35)\n",
      "110958.25137198498\n",
      "(34754, 46)\n",
      "109965.44401216577\n",
      "(34754, 35)\n",
      "109089.74907141076\n",
      "(34754, 36)\n",
      "111819.43397144343\n",
      "(34754, 43)\n",
      "110704.01538188057\n",
      "(34754, 30)\n",
      "112789.30354754183\n",
      "(34754, 41)\n",
      "111998.02225104187\n",
      "(34754, 43)\n",
      "111633.675691919\n",
      "(34754, 46)\n",
      "111201.15687547458\n",
      "(34754, 45)\n",
      "110197.52673477426\n",
      "(34754, 43)\n",
      "110129.47853207744\n",
      "(34754, 41)\n",
      "111557.12024122175\n",
      "(34754, 38)\n",
      "110653.11670006787\n",
      "(34754, 42)\n",
      "114381.47376381622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34754, 38)\n",
      "111302.93804815794\n",
      "(34754, 35)\n",
      "110712.06213626647\n",
      "(34754, 45)\n",
      "110925.22028383009\n",
      "(34754, 36)\n",
      "112637.38529689159\n",
      "(34754, 38)\n",
      "113663.95247702404\n",
      "(34754, 33)\n",
      "113071.62580857471\n",
      "(34754, 42)\n",
      "112013.33595779701\n",
      "(34754, 45)\n",
      "111175.58923838158\n",
      "(34754, 37)\n",
      "110802.01023727261\n",
      "(34754, 44)\n",
      "109630.29889216965\n",
      "(34754, 38)\n",
      "111911.35660333198\n",
      "(34754, 36)\n",
      "110214.98771509413\n",
      "(34754, 47)\n",
      "111990.14222046133\n",
      "(34754, 37)\n",
      "114309.0431684354\n",
      "(34754, 50)\n",
      "111553.90481715047\n",
      "(34754, 41)\n",
      "112560.05973141149\n",
      "(34754, 39)\n",
      "114097.41376013566\n",
      "(34754, 41)\n",
      "110913.88370294205\n",
      "(34754, 45)\n",
      "110418.36168772163\n",
      "(34754, 42)\n",
      "112722.4150711151\n",
      "(34754, 43)\n",
      "114566.32316246083\n",
      "(34754, 37)\n",
      "109424.50594126836\n",
      "(34754, 39)\n",
      "112256.61529787634\n",
      "(34754, 38)\n",
      "111448.30743707938\n",
      "(34754, 40)\n",
      "111650.72298409203\n",
      "(34754, 42)\n",
      "114034.43054689665\n",
      "(34754, 36)\n",
      "113030.64879278924\n",
      "(34754, 41)\n",
      "110989.36295803628\n",
      "(34754, 45)\n",
      "110403.71918299545\n",
      "(34754, 43)\n",
      "113105.79274477942\n",
      "(34754, 47)\n",
      "110593.1430295115\n",
      "(34754, 40)\n",
      "111424.89055101297\n",
      "(34754, 38)\n",
      "111997.01674234966\n",
      "(34754, 47)\n",
      "111168.92023021025\n",
      "(34754, 43)\n",
      "109662.08348292133\n",
      "(34754, 40)\n",
      "110439.05855972547\n",
      "(34754, 29)\n",
      "115345.5395195828\n",
      "(34754, 34)\n",
      "111294.78377213488\n",
      "(34754, 40)\n",
      "110753.52087930898\n",
      "(34754, 40)\n",
      "110582.24985512978\n",
      "(34754, 32)\n",
      "112553.65092525915\n",
      "(34754, 36)\n",
      "110611.32171844153\n",
      "(34754, 42)\n",
      "112285.59481231381\n",
      "(34754, 43)\n",
      "111218.3166121067\n",
      "(34754, 40)\n",
      "112183.51595900509\n",
      "(34754, 38)\n",
      "112795.13361011136\n",
      "(34754, 34)\n",
      "109797.33674283705\n",
      "(34754, 43)\n",
      "110299.16296836766\n",
      "(34754, 43)\n",
      "111159.76544800693\n",
      "(34754, 47)\n",
      "112438.06235619908\n",
      "(34754, 37)\n",
      "112744.93653522921\n",
      "(34754, 34)\n",
      "112728.34318485252\n",
      "(34754, 34)\n",
      "110531.4792733822\n",
      "(34754, 48)\n",
      "111290.43997559095\n",
      "(34754, 52)\n",
      "112042.8864393085\n",
      "(34754, 43)\n",
      "112185.56460066159\n",
      "(34754, 37)\n",
      "115652.02577456729\n",
      "(34754, 50)\n",
      "108998.65978442246\n",
      "(34754, 43)\n",
      "111289.10219495761\n",
      "(34754, 32)\n",
      "112310.32065420758\n",
      "(34754, 40)\n",
      "114164.56383453101\n",
      "(34754, 37)\n",
      "112989.52419568523\n",
      "(34754, 40)\n",
      "110918.7077193997\n",
      "(34754, 42)\n",
      "111950.1434075125\n",
      "(34754, 50)\n",
      "112060.54606856301\n",
      "(34754, 32)\n",
      "112262.7223314659\n",
      "(34754, 41)\n",
      "111376.4189630714\n",
      "(34754, 40)\n",
      "110337.88237540562\n",
      "(34754, 30)\n",
      "115351.04773195695\n",
      "(34754, 39)\n",
      "111104.80905623715\n",
      "(34754, 37)\n",
      "110983.0372095174\n",
      "(34754, 34)\n",
      "111503.73004716002\n",
      "(34754, 52)\n",
      "110432.13424451668\n",
      "(34754, 40)\n",
      "112132.14011729462\n",
      "(34754, 47)\n",
      "110069.85358686247\n",
      "(34754, 38)\n",
      "110952.0817873399\n",
      "(34754, 40)\n",
      "110249.84194340958\n",
      "(34754, 33)\n",
      "113206.36457459757\n",
      "(34754, 46)\n",
      "110272.34674474127\n",
      "(34754, 39)\n",
      "111918.2195784425\n",
      "(34754, 41)\n",
      "111567.87753167331\n",
      "(34754, 42)\n",
      "109867.96180848259\n",
      "(34754, 40)\n",
      "114610.18777708482\n",
      "(34754, 35)\n",
      "113198.8443076461\n",
      "(34754, 44)\n",
      "112033.17734990339\n",
      "(34754, 38)\n",
      "110435.7558323485\n",
      "(34754, 43)\n",
      "112028.55016844456\n",
      "(34754, 37)\n",
      "111122.91085258021\n",
      "(34754, 25)\n",
      "112847.10966935543\n",
      "(34754, 40)\n",
      "113812.60551725433\n",
      "(34754, 42)\n",
      "113867.15818415167\n",
      "(34754, 46)\n",
      "114121.0822224835\n",
      "(34754, 39)\n",
      "110457.33194590731\n",
      "(34754, 48)\n",
      "111084.91758534663\n",
      "(34754, 34)\n",
      "112092.38169679992\n",
      "(34754, 35)\n",
      "109908.61207343565\n",
      "(34754, 39)\n",
      "113014.60168320677\n",
      "(34754, 41)\n",
      "114627.80393507685\n",
      "(34754, 47)\n",
      "110279.8444551749\n",
      "(34754, 38)\n",
      "112805.60788143025\n",
      "(34754, 40)\n",
      "110163.86075614199\n",
      "(34754, 35)\n",
      "110831.31792375052\n",
      "(34754, 34)\n",
      "109572.56909301819\n",
      "(34754, 35)\n",
      "111853.96945747409\n",
      "(34754, 33)\n",
      "113029.96496687832\n",
      "(34754, 35)\n",
      "114817.28271622089\n",
      "(34754, 45)\n",
      "109241.94966325602\n",
      "(34754, 43)\n",
      "110252.70460886163\n",
      "(34754, 36)\n",
      "111148.22717210013\n",
      "(34754, 42)\n",
      "110418.23572497767\n",
      "(34754, 36)\n",
      "112160.42403140118\n",
      "(34754, 37)\n",
      "112087.7537158295\n",
      "(34754, 40)\n",
      "110347.88568916245\n",
      "(34754, 41)\n",
      "111104.22113475596\n",
      "(34754, 41)\n",
      "111747.07089149414\n",
      "(34754, 44)\n",
      "112327.23508826239\n",
      "(34754, 45)\n",
      "109446.92887857519\n",
      "(34754, 47)\n",
      "113263.25561352025\n",
      "(34754, 47)\n",
      "111758.16076648056\n",
      "(34754, 41)\n",
      "111823.69495933379\n",
      "(34754, 33)\n",
      "108795.25342434406\n",
      "(34754, 48)\n",
      "108264.32081250093\n",
      "(34754, 36)\n",
      "111926.50163446197\n",
      "(34754, 40)\n",
      "110138.90851727479\n",
      "(34754, 37)\n",
      "110166.08210173719\n",
      "(34754, 47)\n",
      "110730.61885708048\n",
      "(34754, 38)\n",
      "110954.08853714791\n",
      "(34754, 43)\n",
      "112563.08760826668\n",
      "(34754, 41)\n",
      "110145.85488972743\n",
      "(34754, 38)\n",
      "111680.6538684556\n",
      "(34754, 38)\n",
      "112065.58735611974\n",
      "(34754, 37)\n",
      "112148.12078547444\n",
      "(34754, 35)\n",
      "109020.77905130865\n",
      "(34754, 39)\n",
      "112044.74748384\n",
      "(34754, 47)\n",
      "113125.83197207142\n",
      "(34754, 42)\n",
      "110740.21092580019\n",
      "(34754, 46)\n",
      "111330.43168252925\n",
      "(34754, 35)\n",
      "112192.65124530673\n",
      "(34754, 41)\n",
      "109878.05803943065\n",
      "(34754, 36)\n",
      "110210.20770184319\n",
      "(34754, 35)\n",
      "113814.92326057656\n",
      "(34754, 41)\n",
      "111035.60608591231\n",
      "(34754, 41)\n",
      "112161.24789017106\n",
      "(34754, 45)\n",
      "110163.36534422995\n",
      "(34754, 43)\n",
      "110652.75927504369\n",
      "(34754, 40)\n",
      "109272.07879918639\n",
      "(34754, 47)\n",
      "111647.2845563823\n",
      "(34754, 41)\n",
      "110252.43956503784\n",
      "(34754, 35)\n",
      "111652.71473579526\n",
      "(34754, 43)\n",
      "111497.44892479376\n",
      "(34754, 43)\n",
      "114878.61364429921\n",
      "(34754, 38)\n",
      "110527.11391619043\n",
      "(34754, 46)\n",
      "110159.21621949476\n",
      "(34754, 35)\n",
      "112733.33627202977\n",
      "(34754, 42)\n",
      "111784.21601082436\n",
      "(34754, 42)\n",
      "110442.71653883823\n",
      "(34754, 43)\n",
      "110477.45095760543\n",
      "(34754, 40)\n",
      "113032.73182055753\n",
      "(34754, 35)\n",
      "111893.42928696821\n",
      "(34754, 43)\n",
      "111581.56851067748\n",
      "(34754, 45)\n",
      "110720.15963625486\n",
      "(34754, 57)\n",
      "112251.90280143027\n",
      "(34754, 39)\n",
      "112067.88663861755\n",
      "(34754, 41)\n",
      "111365.64812583565\n",
      "(34754, 46)\n",
      "110131.93387321285\n",
      "(34754, 41)\n",
      "113648.50047689394\n",
      "(34754, 42)\n",
      "110665.23509649794\n",
      "(34754, 38)\n",
      "110207.20076338461\n",
      "(34754, 37)\n",
      "111796.52164863264\n",
      "(34754, 40)\n",
      "110533.32455408476\n",
      "(34754, 40)\n",
      "114243.08583523043\n",
      "(34754, 46)\n",
      "109979.987453262\n",
      "(34754, 33)\n",
      "111043.77648475484\n",
      "(34754, 37)\n",
      "110496.61201909305\n",
      "(34754, 45)\n",
      "109846.90706207308\n",
      "(34754, 40)\n",
      "112260.02826126516\n",
      "(34754, 47)\n",
      "113622.1963679559\n",
      "(34754, 38)\n",
      "110950.85565485284\n",
      "(34754, 39)\n",
      "112442.65007600513\n",
      "(34754, 43)\n",
      "112678.9795107968\n",
      "(34754, 35)\n",
      "111493.88592655171\n",
      "(34754, 31)\n",
      "111805.32936001054\n",
      "(34754, 42)\n",
      "112443.56431950635\n",
      "(34754, 39)\n",
      "110647.4621547964\n",
      "(34754, 38)\n",
      "110388.33016459364\n",
      "(34754, 39)\n",
      "110495.40155241806\n",
      "(34754, 41)\n",
      "112427.96534382502\n",
      "(34754, 33)\n",
      "111509.89886459202\n",
      "(34754, 42)\n",
      "111404.20504523792\n",
      "(34754, 47)\n",
      "109822.24726411262\n",
      "(34754, 41)\n",
      "111600.37450516905\n",
      "(34754, 38)\n",
      "114555.5746217365\n",
      "(34754, 32)\n",
      "112507.60135241917\n",
      "(34754, 45)\n",
      "108749.26918435351\n",
      "(34754, 41)\n",
      "113073.2663753465\n",
      "(34754, 40)\n",
      "112452.29795024783\n",
      "(34754, 37)\n",
      "112483.27207110597\n",
      "(34754, 44)\n",
      "111184.09703075816\n",
      "(34754, 41)\n",
      "110115.62438110948\n",
      "optimization results\n",
      "Best Solution is: \n",
      "[1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Best Fitness is: \n",
      "107817.88718845566\n"
     ]
    }
   ],
   "source": [
    "best_solution, best_fitness = pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34754, 40)\n",
      "(11585, 40)\n",
      "109622.54082582005\n",
      "23.37466592646004\n"
     ]
    }
   ],
   "source": [
    "best_feature_selected = [i for i, e in enumerate(best_solution) if e == 1]\n",
    "x_train_new = x_train.iloc[:,best_feature_selected] \n",
    "print(x_train_new.shape)\n",
    "# x_val_new = x_validate.iloc[:,index]\n",
    "\n",
    "regressor=DecisionTreeRegressor(criterion='mse',max_features= 3,min_samples_leaf=2,min_samples_split=8)\n",
    "regressor.fit(x_train_new,y_train)\n",
    "\n",
    "\n",
    "x_test_new = x_test.iloc[:,best_feature_selected]\n",
    "print(x_test_new.shape)\n",
    "yp=regressor.predict(x_test_new)\n",
    "mse = mean_squared_error(y_test,yp)\n",
    "Rmse=m.sqrt(mse)\n",
    "AIC=(34754)*m.log(Rmse)+2*45\n",
    "print(AIC)\n",
    "print(Rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.774940496607307"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546.375007173612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,yp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                               'Total Project Cost',\n",
       "                                                        'Total Incentives',\n",
       "                                         'Amount Financed Through Program',\n",
       "                                                         'Number of Units',\n",
       "                                                        'Home Performance',\n",
       "                                                     'Project County_Erie',\n",
       "                                                  'Project County_Suffolk',\n",
       "                                                 'Project County_Onondaga',\n",
       "                                              'Project County_Westchester',\n",
       "                                                'Project County_Jefferson',\n",
       "                                                   'Project County_Nassau',\n",
       "                                                    'Project City_Buffalo',\n",
       "                                                  'Project City_Watertown',\n",
       "                                                   'Project City_Syracuse',\n",
       "                                                  'Project City_Pittsford',\n",
       "                                                      'Project City_Utica',\n",
       "                                                  'Project City_Tonawanda',\n",
       "                                    'Gas Utility_Rochester Gas & Electric',\n",
       "                                               'Gas Utility_National Grid',\n",
       "                               'Gas Utility_Central Hudson Gas & Electric',\n",
       "                                          'Gas Utility_Saint Lawrence Gas',\n",
       "                                           'Gas Utility_Orange & Rockland',\n",
       "                                         'Gas Utility_Corning Natural Gas',\n",
       "                                             'Gas Utility_No Gas Provider',\n",
       "                               'Electric Utility_Rochester Gas & Electric',\n",
       "                            'Electric Utility_Long Island Power Authority',\n",
       "                          'Electric Utility_Central Hudson Gas & Electric',\n",
       "                                      'Electric Utility_Orange & Rockland',\n",
       "                                                                      2012,\n",
       "                                                                      2014,\n",
       "                                                                      2018,\n",
       "                                                                      2019,\n",
       "       'Type of Program Financing_Green Jobs - Green NY Smart Energy Loan',\n",
       "                                         'Type of Program Financing_ESTAR',\n",
       "                                 'Pre-Retrofit Home Heating Fuel Type_Oil',\n",
       "                             'Pre-Retrofit Home Heating Fuel Type_Propane',\n",
       "                         'Pre-Retrofit Home Heating Fuel Type_Electricity',\n",
       "                                'Pre-Retrofit Home Heating Fuel Type_Wood',\n",
       "                        'Pre-Retrofit Home Heating Fuel Type_Wood Pellets',\n",
       "                            'Pre-Retrofit Home Heating Fuel Type_Kerosene',\n",
       "                     'Pre-Retrofit Home Heating Fuel Type_Bituminous Coal',\n",
       "                     'Pre-Retrofit Home Heating Fuel Type_Anthracite Coal',\n",
       "                                             'Measure Type_Building Shell',\n",
       "                                        'Measure Type_Heating and Cooling',\n",
       "                                               'Measure Type_Water Heater'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (34754, 80) (34754,)\n",
      "Testing dataset shape: (11585, 80) (11585,)\n",
      "Validation dataset shape: (11585, 80) (11585,)\n",
      "(57924, 81)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "#from bga import BGA\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "def Fitness(arr , x_train, y_train , x_validate , y_validate):\n",
    "    index = [i for i, e in enumerate(arr) if e == 1]\n",
    "    index = np.array(index)\n",
    "  \n",
    "    x_train_new = x_train.iloc[:,index] \n",
    "    print(x_train_new.shape)\n",
    "    x_val_new = x_validate.iloc[:,index]\n",
    "   \n",
    "    #regressor=Lasso(alpha=0.05,max_iter=100,normalize=True,tol=0.0001)\n",
    "    #regressor.fit(x_train_new,y_train)\n",
    "    #Lasso(alpha=1.0,max_iter=1000,normalize=False,tol=0.0001,fit_intercept=True,precompute=False,copy_X=True,warm_start=False,positive=False,random_state=None,selection='cyclic')\n",
    "    #regressor=DecisionTreeRegressor(criterion='friedman_mse',max_features= 3,min_samples_leaf=5,min_samples_split=12)\n",
    "    regressor=RandomForestRegressor(max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "    regressor.fit(x_train_new,y_train)#criterion=friedman_mse,max_features=3,min_samples_leaf=5,min_samples_split=12\n",
    "    #DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
    "     #                   max_features=2, max_leaf_nodes=None,\n",
    "      #                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       #                 min_samples_leaf=1, min_samples_split=2,\n",
    "        #                min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "         #               random_state=None, splitter='best')\n",
    "    yp=regressor.predict(x_val_new)\n",
    "    mse = mean_squared_error(y_validate,yp)\n",
    "    Rmse=m.sqrt(mse)\n",
    "    AIC=(34754)*m.log(Rmse)+2*len(index)\n",
    "    print(AIC)\n",
    "    return  AIC \n",
    "\n",
    "train,validate,test=np.split(df1.sample(frac=1),[int(.6*len(df1)),int(.8*len(df1))])\n",
    "x_train=train.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_train=train.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_test=test.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_test=test.loc[:,'Estimated Annual MMBtu Savings']\n",
    "x_validate=validate.drop('Estimated Annual MMBtu Savings',1)\n",
    "y_validate=validate.loc[:,'Estimated Annual MMBtu Savings']\n",
    "\n",
    "\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', x_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', x_test.shape, y_test.shape)\n",
    "print('Validation dataset shape:', x_validate.shape, y_validate.shape)\n",
    "print(df1.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)\n",
    "# best_solution, best_fitness = pso.run()\n",
    "\n",
    "# call BGA\n",
    "#test = BGA( x_train, y_train , x_test , y_test, pop_shape=(num_pop, problem_dimentions), method=Fitness, p_c=0.8, p_m=0.2, maxiter = 100, early_stop_rounds=None, verbose = None, maximum=False)\n",
    "\n",
    "# Run BGA\n",
    "#best_solution, best_fitness = test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimentions = 80\n",
    "num_particles = 100\n",
    "maxiter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "(34754, 36)\n",
      "107495.64609437763\n",
      "(34754, 44)\n",
      "112562.04788739758\n",
      "(34754, 40)\n",
      "106053.38645946754\n",
      "(34754, 38)\n",
      "110009.39503176711\n",
      "(34754, 42)\n",
      "110433.64792642898\n",
      "(34754, 42)\n",
      "107560.2723031212\n",
      "(34754, 45)\n",
      "106972.9978590661\n",
      "(34754, 35)\n",
      "110058.83231999281\n",
      "(34754, 40)\n",
      "111857.29415697268\n",
      "(34754, 40)\n",
      "109166.11551849241\n",
      "(34754, 34)\n",
      "108853.83169324687\n",
      "(34754, 40)\n",
      "107572.4755177707\n",
      "(34754, 40)\n",
      "107521.98550510593\n",
      "(34754, 42)\n",
      "108443.20765311646\n",
      "(34754, 39)\n",
      "108955.63522195035\n",
      "(34754, 38)\n",
      "110547.18541102363\n",
      "(34754, 41)\n",
      "109842.15310647685\n",
      "(34754, 35)\n",
      "109055.65883969508\n",
      "(34754, 46)\n",
      "112176.79519574068\n",
      "(34754, 44)\n",
      "110085.70984729206\n",
      "(34754, 45)\n",
      "107357.72376820304\n",
      "(34754, 33)\n",
      "111530.05557823667\n",
      "(34754, 44)\n",
      "109160.32381755604\n",
      "(34754, 43)\n",
      "106266.92668619794\n",
      "(34754, 40)\n",
      "111143.88742691826\n",
      "(34754, 49)\n",
      "107364.01291885648\n",
      "(34754, 36)\n",
      "110923.61180090482\n",
      "(34754, 41)\n",
      "107989.40457954576\n",
      "(34754, 34)\n",
      "106309.43180338526\n",
      "(34754, 43)\n",
      "107123.54188688868\n",
      "(34754, 41)\n",
      "109008.77282258356\n",
      "(34754, 42)\n",
      "107402.63038804888\n",
      "(34754, 43)\n",
      "105273.87104378118\n",
      "(34754, 40)\n",
      "106419.19270289078\n",
      "(34754, 35)\n",
      "111487.74992789545\n",
      "(34754, 32)\n",
      "106778.16479599761\n",
      "(34754, 48)\n",
      "106756.90909277016\n",
      "(34754, 41)\n",
      "108579.0209312382\n",
      "(34754, 38)\n",
      "109681.43449765183\n",
      "(34754, 33)\n",
      "109485.1955291578\n",
      "(34754, 33)\n",
      "106300.37694222445\n",
      "(34754, 35)\n",
      "106676.91767934173\n",
      "(34754, 41)\n",
      "107480.49736736169\n",
      "(34754, 44)\n",
      "108065.15099090645\n",
      "(34754, 39)\n",
      "107633.85717978032\n",
      "(34754, 40)\n",
      "108647.24364355949\n",
      "(34754, 36)\n",
      "111400.69415995396\n",
      "(34754, 40)\n",
      "108811.65438296327\n",
      "(34754, 40)\n",
      "109649.76834725853\n",
      "(34754, 45)\n",
      "107259.66141400511\n",
      "(34754, 43)\n",
      "109950.4646400092\n",
      "(34754, 43)\n",
      "106217.93805844476\n",
      "(34754, 45)\n",
      "109007.47477377251\n",
      "(34754, 33)\n",
      "108246.88517665744\n",
      "(34754, 40)\n",
      "107250.92166553545\n",
      "(34754, 42)\n",
      "106681.23179614017\n",
      "(34754, 41)\n",
      "107799.93775454852\n",
      "(34754, 41)\n",
      "111397.7635572732\n",
      "(34754, 43)\n",
      "106752.63664714155\n",
      "(34754, 41)\n",
      "107657.5751935606\n",
      "(34754, 39)\n",
      "108055.24706947307\n",
      "(34754, 42)\n",
      "108261.84066580902\n",
      "(34754, 37)\n",
      "107163.21647396433\n",
      "(34754, 39)\n",
      "107825.02014418502\n",
      "(34754, 39)\n",
      "108451.47624953391\n",
      "(34754, 35)\n",
      "108150.18206127461\n",
      "(34754, 38)\n",
      "112024.10824516532\n",
      "(34754, 38)\n",
      "111678.10640706395\n",
      "(34754, 41)\n",
      "107484.41156045333\n",
      "(34754, 44)\n",
      "106625.35139518055\n",
      "(34754, 39)\n",
      "107640.65483442068\n",
      "(34754, 44)\n",
      "106266.89667654806\n",
      "(34754, 44)\n",
      "108703.1747662095\n",
      "(34754, 43)\n",
      "108071.07693722911\n",
      "(34754, 36)\n",
      "107784.289749021\n",
      "(34754, 42)\n",
      "107881.48149202799\n",
      "(34754, 41)\n",
      "112946.68874468314\n",
      "(34754, 41)\n",
      "109135.7961063548\n",
      "(34754, 37)\n",
      "106788.9228711409\n",
      "(34754, 45)\n",
      "109009.7614772111\n",
      "(34754, 38)\n",
      "112083.34125941647\n",
      "(34754, 35)\n",
      "106958.10825632853\n",
      "(34754, 44)\n",
      "110382.03983453916\n",
      "(34754, 45)\n",
      "107506.89413935131\n",
      "(34754, 44)\n",
      "107748.92790527407\n",
      "(34754, 43)\n",
      "106863.61438141338\n",
      "(34754, 35)\n",
      "107512.01455901506\n",
      "(34754, 41)\n",
      "109616.49095251122\n",
      "(34754, 43)\n",
      "107475.15279502998\n",
      "(34754, 37)\n",
      "109342.42128267436\n",
      "(34754, 45)\n",
      "107029.04888717143\n",
      "(34754, 39)\n",
      "109708.22642943125\n",
      "(34754, 48)\n",
      "106628.76882652253\n",
      "(34754, 34)\n",
      "112169.16934843302\n",
      "(34754, 39)\n",
      "107147.65253264016\n",
      "(34754, 29)\n",
      "109480.49787463293\n",
      "(34754, 45)\n",
      "106874.69410699983\n",
      "(34754, 37)\n",
      "107415.77983635674\n",
      "(34754, 42)\n",
      "112747.563089003\n",
      "(34754, 35)\n",
      "107022.72135439902\n",
      "optimization results\n",
      "Best Solution is: \n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "Best Fitness is: \n",
      "105273.87104378118\n"
     ]
    }
   ],
   "source": [
    "best_solution, best_fitness = pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34754, 43)\n",
      "(11585, 43)\n",
      "104586.75717364773\n",
      "20.24262797340292\n"
     ]
    }
   ],
   "source": [
    "best_feature_selected = [i for i, e in enumerate(best_solution) if e == 1]\n",
    "x_train_new = x_train.iloc[:,best_feature_selected] \n",
    "print(x_train_new.shape)\n",
    "# x_val_new = x_validate.iloc[:,index]\n",
    "\n",
    "regressor=RandomForestRegressor(max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "regressor.fit(x_train_new,y_train)\n",
    "\n",
    "\n",
    "x_test_new = x_test.iloc[:,best_feature_selected]\n",
    "print(x_test_new.shape)\n",
    "yp=regressor.predict(x_test_new)\n",
    "mse = mean_squared_error(y_test,yp)\n",
    "Rmse=m.sqrt(mse)\n",
    "AIC=(34754)*m.log(Rmse)+2*27\n",
    "print(AIC)\n",
    "print(Rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                                   'Total Project Cost',\n",
       "                                                            'Total Incentives',\n",
       "                                             'Amount Financed Through Program',\n",
       "                                                             'Year Home Built',\n",
       "                                                                'Size of Home',\n",
       "                                                              'Volume of Home',\n",
       "                                                               'Customer Type',\n",
       "                                                            'Home Performance',\n",
       "                                                  'Project County_Westchester',\n",
       "                                                       'Project County_Oneida',\n",
       "                                                       'Project County_Nassau',\n",
       "                                                        'Project County_Wayne',\n",
       "                                                        'Project City_Webster',\n",
       "                                                      'Project City_Fort Drum',\n",
       "                                                         'Project City_Ithaca',\n",
       "                                                      'Project City_Tonawanda',\n",
       "                                  'Gas Utility_National Fuel Gas Distribution',\n",
       "                                              'Gas Utility_Saint Lawrence Gas',\n",
       "                                          'Gas Utility_Multiple Gas Providers',\n",
       "                                                 'Gas Utility_No Gas Provider',\n",
       "                                              'Electric Utility_National Grid',\n",
       "                                        'Electric Utility_Consolidated Edison',\n",
       "                              'Electric Utility_Central Hudson Gas & Electric',\n",
       "                                  'Electric Utility_Municipal (Not Qualified)',\n",
       "                                                                          2010,\n",
       "                                                                          2011,\n",
       "                                                                          2012,\n",
       "                                                                          2013,\n",
       "                                                                          2014,\n",
       "                                                                          2016,\n",
       "                                                                          2017,\n",
       "                                                                          2018,\n",
       "                                      'Type of Program Financing_not financed',\n",
       "       'Type of Program Financing_Green Jobs - Green NY On-Bill Recovery Loan',\n",
       "                                            'Type of Program Financing_ESMART',\n",
       "                             'Pre-Retrofit Home Heating Fuel Type_Natural Gas',\n",
       "                                     'Pre-Retrofit Home Heating Fuel Type_Oil',\n",
       "                                 'Pre-Retrofit Home Heating Fuel Type_Propane',\n",
       "                             'Pre-Retrofit Home Heating Fuel Type_Electricity',\n",
       "                                    'Pre-Retrofit Home Heating Fuel Type_Wood',\n",
       "                                'Pre-Retrofit Home Heating Fuel Type_Kerosene',\n",
       "                                    'Pre-Retrofit Home Heating Fuel Type_Coal',\n",
       "                                                   'Measure Type_Water Heater'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
